services:
  #============================================================
  # BACKEND - AI Services
  #============================================================
  ai-service-openai-proto-generator:
    build:
      context: ./backend/ai-service-openai
      dockerfile: Dockerfile.dev
    volumes:
      - ./backend/ai-service-openai/proto:/proto
      - ./backend/ai-service-openai/app/proto:/app/proto
    entrypoint: [ "python3", "app/helper_proto_generator.py" ]
    profiles:
      - ai
      - backend
      - fullstack

  ai-service-api-openai:
    build:
      context: ./backend/ai-service-openai
      dockerfile: Dockerfile.dev
    env_file:
      - ./backend/ai-service-openai/ai-service-api-openai.env
    command: [ "python3", "/app/entrypoint_dev.py" ]
    ports:
      - "${PORT:-50061}:${PORT:-50061}"
    volumes:
      - ./backend/ai-service-openai:/app
    depends_on:
      - ai-service-openai-proto-generator
      - ai-service-rabbitmq
      - ai-service-openai-rate-limit-postgres
    profiles:
      - ai
      - backend
      - fullstack

  ai-service-worker-openai:
    build:
      context: ./backend/ai-service-openai
      dockerfile: Dockerfile.dev
    env_file:
      - ./backend/ai-service-openai/ai-service-worker-openai.env
    command: [ "python3", "/app/entrypoint_dev.py" ]
    depends_on:
      - ai-service-rabbitmq
      - ai-service-openai-proto-generator
    volumes:
      - ./backend/ai-service-openai:/app
    profiles:
      - ai
      - backend
      - fullstack

  ai-service-rabbitmq:
    image: rabbitmq:3-management
    env_file:
      - ./backend/ai-service-rabbitmq.env
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "ping" ]
      interval: 5s
      timeout: 10s
      retries: 5
    ports:
      - "5672:5672"
      - "15672:15672"
    profiles:
      - ai
      - backend
      - fullstack

  ai-service-openai-rate-limit-postgres:
    image: postgres:latest
    env_file:
      - ./backend/ai-service-rate-limit-postgres.env
    ports:
      - "55434:5432"
    volumes:
      - ai-service-openai-rate-limit-postgres-data:/var/lib/postgresql/data
    profiles:
      - ai
      - backend
      - fullstack

  #============================================================
  # BACKEND - Dialogue Service
  #============================================================
  dialogue-service:
    build:
      context: ./backend/dialogue-service
      dockerfile: Dockerfile.dev
    env_file:
      - ./backend/dialogue-service/dialogue-service.env
    ports:
      - "${PORT:-50053}:${PORT:-50053}"
    depends_on:
      - ai-service-api-openai
      - dialogue-state-redis
    profiles:
      - backend
      - fullstack

  dialogue-state-redis:
    image: redis:latest
    env_file:
      - ./backend/dialogue-service/dialogue-service.env
    ports:
      - "${REDIS_PORT:-6380}:6379"
    profiles:
      - backend
      - fullstack

  #============================================================
  # BACKEND - Content Services
  #============================================================
  content-service-proto-generator:
    image: node:18
    container_name: content_service_proto_generator
    working_dir: /usr/src/app
    volumes:
      - ./backend/content-service:/usr/src/app
    command: sh -c "npm install && npm run proto:generate"
    profiles:
      - backend
      - fullstack

  content-service:
    build:
      context: ./backend/content-service
      dockerfile: Dockerfile.dev
    env_file:
      - ./backend/content-service/content-service.env
    container_name: content_service
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    restart: always
    ports:
      - "${PORT:-50051}:${PORT:-50051}"
    volumes:
      - ./backend/content-service:/usr/src/app
      - /usr/src/app/node_modules
    depends_on:
      - world-db
      - campaign-db
      - content-service-proto-generator
    profiles:
      - fullstack
      - backend

  #============================================================
  # BACKEND - gRPC Proxy (for Frontend mainly)
  #============================================================
  envoy:
    image: envoyproxy/envoy:v1.22.0
    container_name: envoy_proxy
    restart: always
    env_file:
      - ./envoy/envoy.env
    ports:
      - "${FRONTEND_UI_PORT:-8080}:8080"
      - "${ENVOY_ADMIN_PORT:-9901}:9901"
    volumes:
      - ./envoy/envoy.yaml:/etc/envoy/envoy.yaml
      - ./envoy/envoy_access.log:/var/log/envoy/envoy_access.log
    profiles:
      - envoy
      - fullstack

  #============================================================
  # DATABASES
  #============================================================
  world-db:
    image: postgres:14
    env_file:
      - ./backend/world-db.env
    container_name: world_db
    restart: always
    ports:
      - "55432:5432"
    volumes:
      - world_db_data:/var/lib/postgresql/data
    profiles:
      - database
      - fullstack
      - backend

  campaign-db:
    image: postgres:14
    container_name: campaign_db
    restart: always
    env_file:
      - ./backend/campaign-db.env
    ports:
      - "55433:5432"
    volumes:
      - campaign_db_data:/var/lib/postgresql/data
    profiles:
      - database
      - fullstack
      - backend

  #============================================================
  # FRONTEND - World Building
  #============================================================
  world-building-ui-proto-generator:
    image: node:18
    container_name: world_building_ui_proto_generator
    working_dir: /usr/src/app
    volumes:
      - ./frontend/world-building-ui:/usr/src/app
    command: sh -c "npm install && npm run proto:generate"
    profiles:
      - frontend
      - fullstack
    depends_on:
      - world-db
      - campaign-db

  world-building-ui-frontend:
    build:
      context: ./frontend/world-building-ui
      dockerfile: Dockerfile.dev
    env_file:
      - ./frontend/world-building-ui/world-building-ui.env
    container_name: world_building_ui
    restart: always
    ports:
      - "${FRONTEND_UI_PORT:-3001}:3000"
    volumes:
      - ./frontend/world-building-ui:/usr/src/app
    depends_on:
      - world-building-ui-proto-generator
    profiles:
      - frontend
      - fullstack

#============================================================
# VOLUMES
#============================================================
volumes:
  world_db_data:
  campaign_db_data:
  ai-service-openai-rate-limit-postgres-data:
